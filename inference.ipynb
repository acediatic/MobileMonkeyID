{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PATH_TO_MODEL_DIR = Path('models/research/object_detection/inference_graph')\n",
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR / \"saved_model\"\n",
    "PATH_TO_LABELS = Path('label_map.pbtxt')\n",
    "\n",
    "PATH_TO_IMAGES = Path('data/train eval 1/eval/images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from object_detection.utils import ops as utils_ops\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Saved Inference Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done! Took 21.018110990524292 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(str(PATH_TO_SAVED_MODEL))\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(str(PATH_TO_LABELS),\n",
    "                                                                    use_display_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMG_1718_00108006.jpg', 'IMG_1718_00108017.jpg', 'IMG_1724_00057604.jpg', 'IMG_1724_00057753.jpg', 'IMG_1724_00057763.jpg', 'IMG_1726_00057640.jpg', 'IMG_1726_00057645.jpg', 'IMG_1727_00108005.jpg', 'IMG_1727_00108100.jpg', 'IMG_1729_00108521.jpg']\n"
     ]
    }
   ],
   "source": [
    "image_paths = [PATH_TO_IMAGES /\n",
    "               file for file in os.listdir(PATH_TO_IMAGES) if file.endswith('.jpg')]\n",
    "\n",
    "print([img.name for img in image_paths[:10]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference for :  data\\train eval 1\\eval\\images\\IMG_1741_00108115.jpg\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from cv2 import imshow as cv2_imshow\n",
    "\n",
    "\n",
    "for image_path in [random.choice(image_paths)]:\n",
    "\n",
    "    print(\"Running inference for : \", image_path)\n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop(\"num_detections\"))\n",
    "\n",
    "    # detections = {key: value[0, :num_detections].numpy()\n",
    "    #             for key, value in detections.items()}\n",
    "\n",
    "    import itertools\n",
    "    detections = dict(itertools.islice(detections.items(), num_detections))\n",
    "\n",
    "    detections[\"num_detections\"] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    # detections[\"detection_classes\"] = detections[\"detection_classes\"].astype(np.int64)\n",
    "\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    # Handle models with masks:\n",
    "    if \"detection_masks\" in detections:\n",
    "        # Reframe the the bbox mask to the image size.\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detections[\"detection_masks\"][0], detections[\"detection_boxes\"][0],\n",
    "            image_np.shape[0], image_np.shape[1])\n",
    "        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                           tf.uint8)\n",
    "        detections[\"detection_masks_reframed\"] = detection_masks_reframed.numpy()\n",
    "\n",
    "    boxes = np.asarray(detections[\"detection_boxes\"][0])\n",
    "    classes = np.asarray(detections[\"detection_classes\"][0]).astype(np.int64)\n",
    "    scores = np.asarray(detections[\"detection_scores\"][0])\n",
    "    mask = np.asarray(detections[\"detection_masks_reframed\"])\n",
    "\n",
    "    # Visualizing the results\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_detections,\n",
    "        boxes,\n",
    "        classes,\n",
    "        scores,\n",
    "        category_index,\n",
    "        instance_masks=mask,\n",
    "        use_normalized_coordinates=True,\n",
    "        skip_boxes=True,\n",
    "        skip_scores=True,\n",
    "        skip_labels=True,\n",
    "        line_thickness=3)\n",
    "\n",
    "    viz_utils.save_image_array_as_png(\n",
    "        image_np_with_detections, \"test_image.jpg\")\n",
    "\n",
    "    # cv2_imshow(image_np_with_detections)\n",
    "    # display(Image.fromarray(image_np_with_detections))\n",
    "    print(\"Done\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "257c4cd991efb1dfecf7d57c38dbfa0182696467497229cfbb339021174fedfc"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('MaskRCNN': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
